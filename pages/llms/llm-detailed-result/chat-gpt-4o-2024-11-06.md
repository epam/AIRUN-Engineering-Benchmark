# ChatGPT-4o (2024-11-06)

## Introduction

This article presents an analysis of various code-related tasks performed by the ChatGPT-4o language model. We'll examine the model's performance across different categories, like translation, generation and documentation.

## Evaluation Summary

The following table provides detailed information on each experiment conducted. It includes the type of experiment, category, programming language, dataset used, complexity, input and output sizes, time taken, and accuracy and completeness

| Experiment         | Category                        | Language | Dataset           | Complexity | Size  | Input | Reasons | Output | Time  | Accuracy | Completeness |
|--------------------|---------------------------------|----------|-------------------|------------|-------|-------|---------|--------|-------|----------|--------------|
| code_translation   | ReactToAngular                  | React    | ToDoApp_ReactJS   | high       | avg   | 3269  | 0       | 2292   | 29.92 | 4        | 4            |
| code_translation   | jQueryToReact                   | jQuery   | ToDoApp_jQuery    | high       | low   | 2343  | 0       | 2172   | 25.04 | 4        | 2.5          |
| code_translation   | AngularToReact                  | Angular  | AngularCosmoPage  | avg        | high  | 5413  | 0       | 1868   | 23.10 | 4        | 3.01         |
| code_translation   | UpdateReact                     | React    | ToDoApp_ReactJS   | high       | avg   | 3258  | 0       | 2354   | 26.40 | 4        | 4            |
| code_translation   | UpdateAngular                   | Angular  | ToDoApp_AngularJS | avg        | avg_2 | 2275  | 0       | 2263   | 21.55 | 3.68     | 3.01         |
| code_translation   | ReactToAngular                  | React    | ReactSignUp       | high       | low   | 1273  | 0       | 1630   | 16.64 | 2.65     | 4            |
| code_translation   | VanillaToReact                  | NativeJS | Piano_NativeJS    | high       | low   | 1402  | 0       | 1528   | 14.92 | 4        | 4            |
| code_generation    | ModifyReactApp                  | React    | ReactFetchAPI     | avg        | low   | 379   | 0       | 566    | 6.28  | 4        | 4            |
| code_generation    | GenerateBaseComponent           | none     | none              | none       | none  | 199   | 0       | 1351   | 16.85 | 3        | 4            |
| code_generation    | GenerateReactApp                | none     | none              | none       | none  | 188   | 0       | 803    | 9.99  | 3.38     | 4            |
| code_generation    | WriteTestsForLegacyCode         | React    | ReactSignUp       | high       | low   | 1230  | 0       | 1210   | 11.71 | 3.08     | 2.85         |
| code_generation    | WriteTestsForLegacyCode         | React    | ToDoApp_ReactJS   | high       | avg   | 3226  | 0       | 1494   | 20.20 | 4        | 2.01         |
| code_generation    | WriteTestsForLegacyCode         | Angular  | AngularCosmoPage  | avg        | high  | 5389  | 0       | 1282   | 13.01 | 3.04     | 1.9          |
| code_generation    | WriteTestsForActualCode         | React    | ReactSelect       | extra_high | high  | 15764 | 0       | 1439   | 18.84 | 4        | 4            |
| code_documentation | BusinessFunctionality           | React    | ReactSignUp       | high       | low   | 1223  | 0       | 1188   | 14.11 | 2.88     | 3.02         |
| code_documentation | BusinessFunctionality           | React    | ToDoApp_ReactJS   | high       | avg   | 3219  | 0       | 1199   | 12.56 | 4        | 4            |
| code_documentation | BusinessFunctionality           | Angular  | AngularCosmoPage  | avg        | high  | 5382  | 0       | 1231   | 15.57 | 4        | 4            |
| code_documentation | EvaluateCodeQuality             | React    | ReactSignUp       | high       | low   | 1347  | 0       | 2132   | 24.22 | 4        | 3            |
| code_documentation | EvaluateCodeQuality             | React    | ToDoApp_ReactJS   | high       | avg   | 3343  | 0       | 2005   | 24.39 | 4        | 4            |
| code_documentation | EvaluateCodeQuality             | Angular  | AngularCosmoPage  | avg        | high  | 5506  | 0       | 2085   | 21.50 | 4        | 4            |
| code_documentation | DescribeTechnicalImplementation | Angular  | AngularCosmoPage  | avg        | high  | 5460  | 0       | 2240   | 29.42 | 4        | 3.38         |
| code_documentation | DescribeTechnicalImplementation | React    | ReactSignUp       | high       | low   | 1301  | 0       | 1298   | 19.11 | 2.98     | 3.22         |
| code_documentation | DescribeTechnicalImplementation | React    | ToDoApp_ReactJS   | high       | avg   | 3297  | 0       | 1930   | 24.81 | 4        | 4            |

_Table 1. Summary of ChatGPT-4o performance across various code-related tasks._

Below is a summary of the overall performance across all experiments:

| Total Input | Total Reasons | Total Output | Total Time (sec) | Token per Second | Experiment cost ($) | Average Accuracy | Average Completeness | 
|-------------|---------------|--------------|------------------|------------------|---------------------|------------------|----------------------|
| 75686       | 0             | 37560        | 440.15           | 85.33            | 0.94                | 3.68             | 3.47                 |                               

_Table 2. ChatGPT-4o performance summary in EPAM's LLMs Benchmark._

This summary shows that ChatGPT-4o has an average accuracy of 3.682 and an average completeness of 3.474 across various code-related tasks. The model processed a total of 75,686 input tokens, generating 37,560 output tokens in 440.15
seconds,
resulting in an average speed of 85.33 tokens per second.

## Detailed Analysis

| Experiment         | Average Accuracy | Average Completeness | Average Time   | Average Tokens | Average Tokens/second |
|--------------------|------------------|----------------------|----------------|----------------|-----------------------|
| Code Translation   | 3.761            | 3.503                | 22.510 seconds | 2015.286       | 89.527                |
| Code Generation    | 3.500            | 3.251                | 13.840 seconds | 1163.571       | 84.071                |
| Code Documentation | 3.762            | 3.624                | 20.633 seconds | 1700.889       | 82.435                |

_Table 3. ChatGPT-4o detailed performance analysis across different categories of code-related tasks._

- Code Translation: ChatGPT-4o performs well in code translation tasks, with an average accuracy of 3.761 and an average completeness of 3.503. The model processes these tasks at an average speed of 89.527 tokens per second. The average
  time taken for code translation tasks is 22.510 seconds, with an average output size of 2015.286 tokens.
- Code Generation: In code generation tasks, ChatGPT-4o has an average accuracy of 3.500 and an average completeness of 3.251. The model processes these tasks at an average speed of 84.071 tokens per second. The average time taken for code
  generation tasks is 13.840 seconds, with an average output size of 1163.571 tokens.
- Code Documentation: For code documentation tasks, ChatGPT-4o achieves an average accuracy of 3.762 and an average completeness of 3.624. The model processes these tasks at an average speed of 82.435 tokens per second. The average time
  taken for code documentation tasks is 20.633 seconds, with an average output size of 1700.889 tokens.

Large Context Instruction Following (LCIF) score: 87.5%

| Experiment       | Accuracy | Completeness | Time        | Input Tokens | Output Tokens |
|------------------|----------|--------------|-------------|--------------|---------------|
| TranslateToReact | 3        | 4            | 104 seconds | 116811       | 7644          |
| UpdateReact      | 4        | 4            | 61 seconds  | 60802        | 3564          |

_Table 4. ChatGPT-4o performance in Large Context Instruction Following (LCIF) tasks._

The model performed well in the LCIF tasks, accurately following the instructions provided. However, there was a minor issue where one file with hooks was lost, causing the code not to run immediately in TranslateToReact task. The tasks
were completed within a reasonable time frame, with a high level of accuracy and completeness.

1. TranslateToReact: The model accurately translated the code from Angular to React with a high level of completeness. The task was completed in 104 seconds, processing 116,811 input tokens and generating 7,644 output tokens.
2. UpdateReact: The model successfully updated the React code with a high level of accuracy and completeness. The task was completed in 61 seconds, processing 60,802 input tokens and generating 3,564 output tokens.

## Conclusion

ChatGPT-4o demonstrates strong performance across various code-related tasks, showcasing its versatility and effectiveness in handling complex programming challenges. Here are the key takeaways from the evaluation:

1. Overall Performance:
    - The model achieves high average scores in both accuracy (3.68) and completeness (3.47) across all experiments, indicating reliable and thorough code manipulation capabilities.
    - With an average processing speed of 85.33 tokens per second, ChatGPT-4o demonstrates efficient performance, especially considering the complexity of the tasks.

2. Code Translation:
    - ChatGPT-4o excels in code translation tasks, with the highest average accuracy (3.761) and tokens/second rate (89.527) among all categories.
    - The model effectively handles translations between various frameworks (React, Angular, jQuery, Vanilla JS), showcasing its versatility.
    - Translation tasks are completed in a reasonable average time of 22.51 seconds, balancing speed and accuracy.

3. Code Generation:
    - In code generation tasks, the model performs well with an average accuracy of 3.500 and completeness of 3.251.
    - ChatGPT-4o shows particular strength in generating React components and modifying existing applications.
    - Generation tasks are processed most quickly, with an average time of 13.84 seconds, demonstrating the model's efficiency in this category.

4. Code Documentation:
    - Documentation tasks see the highest performance, with average accuracy of 3.762 and completeness of 3.624.
    - The model excels in describing business functionality and evaluating code quality across different frameworks.
    - While slightly slower than generation tasks, documentation is still processed efficiently at 82.435 tokens per second.

5. Large Context Instruction Following (LCIF):
    - ChatGPT-4o achieves a solid LCIF score of 87.5%, demonstrating good capability in handling large, complex code bases.
    - The model maintains high accuracy and completeness even with substantial input (over 100,000 tokens in one case), showcasing its ability to manage extensive contexts.
    - A minor issue was noted in the TranslateToReact task, where one file with hooks was lost, indicating a small area for improvement in handling complex translations.

6. Efficiency and Cost-Effectiveness:
    - With an average processing speed of 85.33 tokens per second and a low experiment cost of $0.94, ChatGPT-4o proves to be both efficient and cost-effective.
    - The model's ability to process large amounts of code quickly without sacrificing accuracy makes it suitable for a wide range of development tasks.

7. Areas for Improvement:
    - While generally strong, there's room for improvement in certain specific tasks, such as some aspects of code translation (e.g., ReactToAngular for ReactSignUp had lower accuracy).
    - Consistency in performance across all task types could be enhanced, as there's some variation in accuracy and completeness scores.

In conclusion, ChatGPT-4o proves to be a highly capable model for a wide range of code-related tasks. Its consistent performance across translation, generation, and documentation, coupled with strong LCIF capabilities, makes it a versatile
tool for developers. The model's efficiency in processing complex programming tasks, particularly in code translation and generation, is noteworthy. Its balance of high accuracy, good completeness, and fast processing speed, combined with
cost-effectiveness, positions ChatGPT-4o as a valuable asset for software development workflows. While there are minor areas for potential improvement, the overall performance indicates that ChatGPT-4o is a robust and reliable option for
advanced code manipulation and analysis tasks.

<p style="text-align: center;">
    © 2024 EPAM Systems, Inc. All Rights Reserved.<br/>
    EPAM, EPAM AI/RUN <sup>TM</sup> and the EPAM logo are registered trademarks of EPAM Systems, Inc.<br>
    This report is licensed under CC BY-SA 4.0<br/>
</p>
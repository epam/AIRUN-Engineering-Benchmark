# OpenAI o1-Pro Model Evaluation Report (2025-03-26)

## Executive Summary

OpenAI released its most advanced model, o1-Pro, in late March 2025. This model currently has the highest pricing among all available models, at $150/$600 per 1M input/output tokens. OpenAI has made
this model accessible through their new Responses API, which was designed to accommodate the extended processing time required by o1-Pro, allowing users to check responses later using a request ID.

Our preliminary testing consisted of three experiments, costing approximately $8.5. We estimate the complete evaluation will exceed $60, not including the LCIF experiment, which is projected to cost
an additional $80+. These costs make it difficult to envision widespread practical applications for this model at present. However, o1-Pro will likely be valuable for those seeking to experience
OpenAI's most intelligent model to date.

Currently, this model will primarily appeal to scientific researchers, engineers, and businesses conducting in-depth research requiring advanced reasoning capabilities.

## Test Results

| Experiment         | Type                 | Category                        | Language | Models             | Dataset          | Complexity | Size | Attempt | Input | Reasons | Output | Time   | Accuracy | Completeness |
|--------------------|----------------------|---------------------------------|----------|--------------------|------------------|------------|------|---------|-------|---------|--------|--------|----------|--------------|
| code_translation   | solution_migration   | AngularToReact                  | Angular  | OpenAi_o1_pro_0319 | AngularCosmoPage | avg        | high | 1       | 5849  | 1152    | 5529   | 137.15 | 3.7      | 2.0          |
| code_generation    | component_generation | GenerateReactApp                | none     | OpenAi_o1_pro_0319 | none             | none       | none | 1       | 364   | 768     | 1492   | 121.22 | 4        | 4            |
| code_documentation | code_explanation     | DescribeTechnicalImplementation | Angular  | OpenAi_o1_pro_0319 | AngularCosmoPage | avg        | high | 1       | 5645  | 832     | 4147   | 118.18 | 3.98     | 3.7          |

## Analysis

The test results indicate that the model performs well but not perfectly. In the solution_migration test, the model provided more instructions than ready-to-use code, though the instructions were high
quality. This suggests that the model is more oriented toward research and guidance rather than direct code generation.

The model demonstrated a token generation speed of approximately 29.66 tokens per second, which is significantly slower than most other models in our benchmark. For comparison, Claude 3.7 Sonnet
averages 76.31 tokens per second, while Gemini 2.0 Flash Thinking reaches 188.16 tokens per second. This slow generation speed, combined with the high cost, presents a substantial efficiency challenge
for most practical applications.

The slow token generation speed is likely due to the model's extensive reasoning capabilities, which require significant computational resources and processing time. While this approach may yield
higher quality results for complex reasoning tasks, it creates a substantial tradeoff in terms of efficiency and cost-effectiveness.

## Conclusion

OpenAI o1-Pro demonstrates impressive capabilities but comes with significant cost considerations and performance limitations that will restrict its adoption to specialized use cases. Its primary
value currently lies in research contexts requiring advanced reasoning and problem-solving capabilities rather than everyday development tasks. The combination of extremely high pricing and slow token
generation speed makes it impractical for most standard software engineering applications at this time.
# DeepSeek R1 (2025-01-28)

## Introduction

This article presents an analysis of various code-related tasks performed by the DeepSeek R1 language model, an open-source model designed for self-hosted deployments. We'll examine the model's performance across different categories of
code manipulation, including translation, generation, and documentation, while also considering its unique characteristics as a self-hosted solution.

## Evaluation Summary

| Experiment         | Category                        | Language | Dataset           | Complexity | Size  | Input | Output | Time   | Accuracy | Completeness |
|--------------------|---------------------------------|----------|-------------------|------------|-------|-------|--------|--------|----------|--------------|
| code_translation   | ReactToAngular                  | React    | ToDoApp_ReactJS   | high       | avg   | 3355  | 3720   | 220.29 | 4        | 3.01         |
| code_translation   | jQueryToReact                   | jQuery   | ToDoApp_jQuery    | high       | low   | 2423  | 3468   | 168.97 | 4        | 3.04         |
| code_translation   | AngularToReact                  | Angular  | AngularCosmoPage  | avg        | high  | 5630  | 2845   | 160.73 | 4        | 4            |
| code_translation   | UpdateReact                     | React    | ToDoApp_ReactJS   | high       | avg   | 3345  | 2740   | 147.72 | 4        | 4            |
| code_translation   | UpdateAngular                   | Angular  | ToDoApp_AngularJS | avg        | avg_2 | 2416  | 3993   | 230.29 | 3.06     | 2.95         |
| code_translation   | ReactToAngular                  | React    | ReactSignUp       | high       | low   | 1285  | 2505   | 148.68 | 4        | 3.01         |
| code_translation   | VanillaToReact                  | NativeJS | Piano_NativeJS    | high       | low   | 1423  | 3008   | 167.99 | 4        | 4            |
| code_generation    | ModifyReactApp                  | React    | ReactFetchAPI     | avg        | low   | 376   | 4620   | 274.83 | 4        | 4            |
| code_generation    | GenerateBaseComponent           | none     | none              | none       | none  | 192   | 1357   | 77.46  | 4        | 4            |
| code_generation    | GenerateReactApp                | none     | none              | none       | none  | 183   | 1522   | 69.99  | 2.99     | 3.02         |
| code_generation    | WriteTestsForLegacyCode         | React    | ReactSignUp       | high       | low   | 1242  | 6967   | 407.33 | 3.01     | 3.38         |
| code_generation    | WriteTestsForLegacyCode         | React    | ToDoApp_ReactJS   | high       | avg   | 3312  | 7126   | 370.23 | 4        | 2.32         |
| code_generation    | WriteTestsForLegacyCode         | Angular  | AngularCosmoPage  | avg        | high  | 5605  | 1994   | 117.49 | 2.56     | 0.38         |
| code_generation    | WriteTestsForActualCode         | React    | ReactSelect       | extra_high | high  | 16276 | 2316   | 115.55 | 3.02     | 3.56         |
| code_documentation | BusinessFunctionality           | React    | ReactSignUp       | high       | low   | 1232  | 1159   | 67.16  | 4        | 3.98         |
| code_documentation | BusinessFunctionality           | React    | ToDoApp_ReactJS   | high       | avg   | 3302  | 1373   | 72.41  | 3.02     | 4            |
| code_documentation | BusinessFunctionality           | Angular  | AngularCosmoPage  | avg        | high  | 5595  | 1331   | 82.35  | 4        | 4            |
| code_documentation | EvaluateCodeQuality             | React    | ReactSignUp       | high       | low   | 1358  | 1850   | 128.60 | 4        | 4            |
| code_documentation | EvaluateCodeQuality             | React    | ToDoApp_ReactJS   | high       | avg   | 3428  | 2018   | 113.86 | 4        | 4            |
| code_documentation | EvaluateCodeQuality             | Angular  | AngularCosmoPage  | avg        | high  | 5721  | 1784   | 100.57 | 1.18     | 4            |
| code_documentation | DescribeTechnicalImplementation | Angular  | AngularCosmoPage  | avg        | high  | 5674  | 1661   | 102.90 | 4        | 1.32         |
| code_documentation | DescribeTechnicalImplementation | React    | ReactSignUp       | high       | low   | 1311  | 1836   | 108.54 | 4        | 3.02         |
| code_documentation | DescribeTechnicalImplementation | React    | ToDoApp_ReactJS   | high       | avg   | 3381  | 1819   | 73.65  | 4        | 4            |

Below is a summary of the overall performance across all experiments:

| Total Input | Output | Total Time (sec) | Token per Second* | Experiment cost ($) | Average Accuracy | Average Completeness | 
|-------------|--------|------------------|-------------------|---------------------|------------------|----------------------|
| 78065       | 63012  | 3527.58          | 17.86             | 1.13                | 82.84            | 76.99                |

## Detailed Analysis

| Experiment         | Average Accuracy | Average Completeness | Average Time    | Average Tokens | Average Tokens/second |
|--------------------|------------------|----------------------|-----------------|----------------|-----------------------|
| Code Translation   | 3.866            | 3.430                | 177.810 seconds | 3182.714       | 17.9                  |
| Code Generation    | 3.369            | 2.951                | 204.696 seconds | 3700.286       | 18.077                |
| Code Documentation | 3.578            | 3.591                | 94.448 seconds  | 1647.889       | 17.448                |

The detailed analysis reveals several interesting patterns in DeepSeek R1's performance:

1. Code Translation: The model demonstrates strong capabilities in code translation tasks, achieving an average accuracy of 3.866 and completeness of 3.430. However, these tasks take considerable time (177.81 seconds on average), reflecting
   the model's deliberate processing approach.

2. Code Generation: While showing good accuracy (3.369) and completeness (2.951), code generation tasks require the most processing time (204.696 seconds on average). This suggests that the model invests significant computational effort in
   ensuring quality output for complex generation tasks.

3. Code Documentation: Documentation tasks show balanced performance with accuracy at 3.578 and completeness at 3.591. These tasks are processed more quickly (94.448 seconds on average) while maintaining quality output.

Large Context Instruction Following (LCIF) score: 75%

| Experiment       | Accuracy | Completeness | Time        | Input Tokens | Output Tokens |
|------------------|----------|--------------|-------------|--------------|---------------|
| TranslateToReact | 3        | 3            | 480 seconds | 55676        | 15748         |
| UpdateReact      | 3        | 3            | 397 seconds | 47805        | 12537         |

## Conclusion

DeepSeek R1 demonstrates several notable characteristics and capabilities that position it as a promising option for organizations considering self-hosted LLM solutions:

1. Processing Characteristics:
    - The model uses a CoT (chain of truth) approach, which results in longer processing times but overall high quality results
    - Average token processing speed of 17.86 tokens per second is notably lower than cloud-based alternatives
    - Despite slower processing, the model maintains consistent quality across different task types

2. Performance Strengths:
    - Particularly strong in code translation tasks (3.866 accuracy)
    - Balanced performance in documentation tasks (3.578 accuracy, 3.591 completeness)
    - Maintains reliable accuracy even with complex inputs and larger contexts

3. Deployment Advantages:
    - As an open-source model, it offers full deployment flexibility
    - Suitable for organizations with data privacy requirements or need for offline processing
    - Cost-effective for high-volume usage scenarios, with only infrastructure costs to consider

4. Areas for Consideration:
    - Significantly longer processing times compared to cloud-based alternatives
    - LCIF score of 75% indicates that reasoning models not always suits for such tasks
    - Some variance in performance across different task types

5. Use Case Fit:
    - Best suited for scenarios where processing time is not critical
    - Ideal for organizations prioritizing deployment flexibility and data privacy
    - Strong option for batch processing or non-time-critical development tasks

The model demonstrates that open-source alternatives can deliver professional-grade results, though with different performance characteristics than cloud-based solutions. While the slower processing speed is a notable trade-off, the quality
of output and deployment flexibility make it a viable option for many use cases, particularly where self-hosting and data privacy are priorities.

<p style="text-align: center;">
    Â© 2025 EPAM Systems, Inc. All Rights Reserved.<br/>
    EPAM, EPAM AI/RUN <sup>TM</sup> and the EPAM logo are registered trademarks of EPAM Systems, Inc.<br>
    This report is licensed under CC BY-SA 4.0<br/>
</p>